# README.md

## 1. Постановка задачи  
Сделать чат-бота, который:

1. **Собирает** учебные планы двух магистратур ИТМО  
   * ИИ-инженерия: `https://abit.itmo.ru/program/master/ai`  
   * Управление ИИ-продуктами: `https://abit.itmo.ru/program/master/ai_product`
2. **Отвечает** на все релевантные вопросы абитуриента по содержимому этих планов.
3. **Рекомендует** выборные дисциплины с учётом бэкграунда пользователя.

---

## 2. Стек и библиотеки

| Задача                              | Выбор                                | Причина выбора |
|------------------------------------|--------------------------------------|----------------|
| Парсинг HTML                        | `requests`, `BeautifulSoup`          | Простые страницы, без headless-браузера |
| Извлечение «скрытых» данных         | тег `<script id="__NEXT_DATA__">`    | Структурированный JSON Next.js |
| Загрузка PDF-учебных планов         | `requests`                           | План доступен отдельным REST-эндпоинтом |
| Извлечение текста из PDF            | `PyPDF2`                             | Pure-Python, без C-зависимостей |
| Нормализация PDF-текста             | `re` (RegEx)                         | Требуются эвристики разделения цифр/слов |
| Хранение результатов                | `itmo_programs.json`                 | Для MVP достаточно JSON |
| Чат-интерфейс                       | `python-telegram-bot` v20            | Быстрый запуск long-polling-бота |
| Логика рекомендаций                 | Простые эвристики + словари          | Достаточно для первой версии |

---

## 3. Алгоритм решения

### 3.1 Скрапер (`scraper.py`)

1. **GET→HTML** — скачиваем страницу программы.  
2. Извлекаем JSON-пропсы (`apiProgram.id`) из `__NEXT_DATA__`.  
3. **GET→PDF** — `…/static/programs/{id}/plan/abit/pdf`.  
4. **PyPDF2** — постранично вытягиваем текст.  
5. **RegEx** ищет строки вида 1 Воркшоп по созданию продукта на данных 3108
* «1» — семестр  
* «Воркшоп …» — название  
* «3108» → 3 з.е. и 108 ч.  
6. Отбрасываем «мусорные» заголовки (`пул`, `практика`, `Soft Skills` …).  
7. Сохраняем курсы списком `{name, semester, credits, hours}`.  
8. Сохраняем обе программы в `itmo_programs.json`.

### 3.2 Бот (`bot.py`)

| Интент            | Триггеры                        | Действие |
|-------------------|---------------------------------|----------|
| Сравнение программ| `сравни`, `разниц`, `что лучше` | Возвращает краткое отличие |
| Курсы             | `курс` + опция семестра         | Список курсов выбранной программы |
| Рекомендации      | `рекоменд`, `background` …      | Top-5 курсов по бэкграунду |
| Fallback          | любое прочее                    | Подсказка `/start` |

*Определение программы* — ключевые слова `product / управлен / ai / инженер`.  
*Семестр* — первое число в вопросе (`\b(\d+)\b`).  
*Рекомендации* — скоринг по кластерам «management / development / data_science / design».

### 3.3 Архитектурные решения

| Вопрос                     | Решение | Обоснование |
|----------------------------|---------|-------------|
| HTML vs PDF                | В HTML нет плана             | Забираем PDF |
| Headless-браузер?          | Нет heavy JS                 | Достаточно `requests` |
| LLM-API?                   | MVP оффлайн                  | Эвристики и правила |
| База данных?               | 2 программы                  | JSON-файл |

---

## 4. Запуск

### 4.1 Сбор данных
```bash
python scraper.py        # создаст itmo_programs.json
```
### 4.2 Сбор данных
```bash
export BOT_TOKEN="YOUR_TELEGRAM_BOT_TOKEN"
python bot.py
```
### 4.3 Структура репозитория
Бот стартует в режиме long-polling.
```
├── bot.py               # Telegram-бот
├── scraper.py           # Загрузка и парсинг учебных планов
├── itmo_programs.json   # Полученные данные (создаётся скрапером)
└── README.md            # Этот файл
```
